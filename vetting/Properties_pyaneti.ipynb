{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f10054c1-f9fc-4fe8-9b5a-a2e48c9b6517",
   "metadata": {},
   "source": [
    "# Planet Property Calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80274cf0-6f0a-4f3c-8738-51af98ce3c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "%matplotlib widget\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import lightkurve as lk\n",
    "import math\n",
    "from astropy import units as u\n",
    "from astropy.stats import BoxLeastSquares\n",
    "import numpy as np\n",
    "import warnings\n",
    "import plot_utils as pu\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfe66bb-bae0-4368-82ff-ae5abf819dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output\n",
    "tic = widgets.Text(\n",
    "       value='',\n",
    "       description='TIC:', )\n",
    "menu_author = widgets.Dropdown(\n",
    "       options=['SPOC', '*SPOC*', 'K2', '*'],\n",
    "       value='SPOC',\n",
    "       description='Author:')\n",
    "menu_exptime = widgets.Dropdown(\n",
    "       options=['*', '120', '20', '1800'],\n",
    "       value='*',\n",
    "       description='Exptime:')\n",
    "\n",
    "button_run = widgets.Button(description='Run Query', button_style='primary')\n",
    "out_run = widgets.Output()\n",
    "def on_run_button_clicked(_):\n",
    "    global available_data_select\n",
    "    global TIC_no\n",
    "    global TIC\n",
    "    with out_run:\n",
    "        clear_output()\n",
    "        author = menu_author.value\n",
    "        if menu_exptime.value != '*':\n",
    "            exptime = int(menu_exptime.value)\n",
    "        else:\n",
    "            exptime = menu_exptime.value\n",
    "        TIC_no = tic.value.strip()\n",
    "        TIC = 'TIC ' + TIC_no\n",
    "        print(\"Searching for TIC = {} Author = {} Exptime = {}\".format(TIC,author,exptime))        \n",
    "        # Retrieve the list of available sectors for this TIC\n",
    "        available_data_select = lk.search_lightcurve(TIC, author=author, exptime=exptime)\n",
    "        print(available_data_select)\n",
    "# linking button and function together using a button's method\n",
    "button_run.on_click(on_run_button_clicked)\n",
    "\n",
    "box = widgets.VBox([tic,menu_author,menu_exptime,button_run,out_run ])\n",
    "box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8735f81-15fc-4836-8682-c311c24b91d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output\n",
    "range_sec = widgets.IntRangeSlider(\n",
    "    value=[0, len(available_data_select)],\n",
    "    min=0,\n",
    "    max=len(available_data_select),\n",
    "    step=1,\n",
    "    description='Range:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d',\n",
    ")\n",
    "\n",
    "button_fetch = widgets.Button(description='Fetch Data', button_style='primary')\n",
    "out_fetch = widgets.Output()\n",
    "def on_fetch_button_clicked(_):\n",
    "    global available_data_select\n",
    "    global lc_collection\n",
    "    global sectors\n",
    "    with out_fetch:\n",
    "        clear_output()\n",
    "        # download the data\n",
    "        min_sec = range_sec.value[0]\n",
    "        max_sec = range_sec.value[1]        \n",
    "        print(\"Downloading {} to {}\".format(min_sec,max_sec))\n",
    "        data_select = available_data_select[int(min_sec):int(max_sec)]    \n",
    "        print(data_select)\n",
    "        lc_coll_sel = data_select.download_all()\n",
    "        print(\"Done\")\n",
    "        print(lc_coll_sel)\n",
    "        # 'stitch' the data from the different sectors together (which also normalizes the data)\n",
    "        lc_collection = lc_coll_sel.stitch()\n",
    "        fluxmin = np.nanmin(lc_collection['flux'])\n",
    "        fluxmax = np.nanmax(lc_collection['flux'])\n",
    "        ymax = fluxmax+(fluxmax-1)*0.1\n",
    "        ymin = fluxmin-(fluxmax-1)*0.1      \n",
    "        sectors = []\n",
    "        for x in data_select.mission:\n",
    "            sectors.append(x)\n",
    "        sectors=np.unique(np.char.replace(sectors,\"TESS Sector \",\"\"))\n",
    "        \n",
    "# linking button and function together using a button's method\n",
    "button_fetch.on_click(on_fetch_button_clicked)        \n",
    "print(available_data_select)\n",
    "box1 = widgets.VBox([range_sec,button_fetch,out_fetch ])\n",
    "box1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d90862c-f2e4-4aff-851e-b2ba26f59fb8",
   "metadata": {},
   "source": [
    "# Plot the lightcurve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746d027c-c568-4ed8-be04-f4c826889df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# First with binned data overlay\n",
    "#=================\n",
    "#lc_collection = lc_collection.select_flux(flux_column=\"sap_flux\",flux_err_column=\"sap_flux_err\").normalize() # Switch to SAP Flux if needed (comment out if not)\n",
    "#=================\n",
    "bin_time = 15/24/60\n",
    "lc_binned = lc_collection.bin(bin_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35575db-2237-466e-9f03-84e74c0cc0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default')\n",
    "%matplotlib widget\n",
    "fig, ax = plt.subplots(figsize=(16,6))\n",
    "lc_collection.plot(ax=ax, linewidth=0,marker='o', color='gold',markersize=1, label=\"Flux\")\n",
    "lc_binned.plot(ax=ax, linewidth=0,marker='o', color='black',markersize=1, label=\"Binned\")\n",
    "#lc_collection.bin(20/24/60).plot(ax=ax, color='red')\n",
    "\n",
    "fluxmin = np.nanmin(lc_collection.flux)\n",
    "fluxmax = np.nanmax(lc_collection.flux)\n",
    "ymax = fluxmax+(fluxmax-1)*0.1\n",
    "ymin = fluxmin-(fluxmax-1)*0.1\n",
    "# Reset the max and min\n",
    "#plt.ylim(ymin, ymax)\n",
    "ax.set(title=TIC)\n",
    "pu.add_sector_labels(ax)\n",
    "plt.show()\n",
    "# Define the functions to allow the user to click on two points in the chart\n",
    "coords = []\n",
    "tran = []\n",
    "\n",
    "def onclick(event):\n",
    "    global ix, iy\n",
    "    ix, iy = event.xdata, event.ydata\n",
    "    if event.button == 3:  # Only act on a right click\n",
    "        global coords\n",
    "\n",
    "        if len(coords) == 0:  # remove any existing markers if this is the first click\n",
    "            for i in range(len(tran)):\n",
    "                try: \n",
    "                    tran[i].remove()\n",
    "                except:\n",
    "                    pass\n",
    "            tran.clear()\n",
    "\n",
    "        coords.append((ix, iy))\n",
    "        #arrow_properties = dict(facecolor=\"black\", width=0.5, headwidth=4, shrink=0.1)\n",
    "        #plt.annotate('T%d: x=%8.4f y=%8.4f' %(len(coords),ix, iy), (ix, iy), color='White', fontsize=8, bbox=dict(boxstyle = 'round,pad=0.5'), textcoords=\"offset points\",xytext=(7,-50), arrowprops=arrow_properties)\n",
    "        tran.append(plt.axvline(ix, color = 'purple', zorder = -1))\n",
    "\n",
    "        #if len(coords) == 6:\n",
    "        #    fig.canvas.mpl_disconnect(cid)\n",
    "\n",
    "cid = fig.canvas.mpl_connect('button_press_event', onclick)  # Connect the event\n",
    "\n",
    "button_done = widgets.Button(description='Done', button_style='primary')\n",
    "out_done = widgets.Output()\n",
    "def on_done_button_clicked(_):\n",
    "    global transit_time\n",
    "    global coords\n",
    "    global periods\n",
    "    global starting_period\n",
    "    with out_done:\n",
    "        clear_output()\n",
    "        # User must click at least 2 points - save the x co-ords as the required transit times\n",
    "        # Run this to either accept the points clicked or reset them and try again\n",
    "        if len(coords) < 2:\n",
    "            print (\"Click on at least 2 transits\")\n",
    "        else:\n",
    "            transit_time = []\n",
    "            for i in range(len(coords)):\n",
    "                transit_time.append(coords[i][0])\n",
    "            transit_time.sort()\n",
    "            print (transit_time)\n",
    "            # Tidy up so user can reclick if required\n",
    "            coords.clear()\n",
    "            # the period is the separation between two consecutive transits \n",
    "            periods=[]\n",
    "            for i in range(0,len(transit_time)-1):\n",
    "                periods.append(transit_time[i+1] - transit_time[i])\n",
    "            starting_period = min(periods)\n",
    "            print(periods)\n",
    "            print (\"Starting Period = {} days\".format(starting_period))\n",
    "            print (\"Average = {} days\".format(sum(periods)/len(periods)))            \n",
    "# linking button and function together using a button's method\n",
    "button_done.on_click(on_done_button_clicked)        \n",
    "box2 = widgets.VBox([button_done,out_done ])\n",
    "box2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23ee9dc-d12c-41ae-8f1f-b65dc1a679d8",
   "metadata": {},
   "source": [
    "# STOP Here and look at the light curve\n",
    "- RIGHT Click on the transits - at least 2\n",
    "- Then click Done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdc3d0d-d2e1-4437-a3f6-3d58164da0ea",
   "metadata": {},
   "source": [
    "# Check the background to make sure none of the 'dips' are background spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd097f8-2da1-44d7-a712-1a64858eb267",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "# set up the plotting region\n",
    "fig, axbg = plt.subplots(figsize = (10,5))\n",
    "\n",
    "# plot the time vs the background flux\n",
    "plt.plot(lc_collection.time.value, lc_collection.sap_bkg.value, color = 'blue', lw = 0, marker = '.', ms = 1)\n",
    "\n",
    "plt.ylabel(\"Background flux\") # label the axes\n",
    "plt.xlabel(\"Time (TJD)\")\n",
    "plt.title(\"TIC-\" + TIC_no)\n",
    "plt.tight_layout()\n",
    "for transit in transit_time:\n",
    "    plt.axvline(transit, color = 'lightblue', zorder = -1)\n",
    "print ('\\033[1mBackground flux for sector\\033[0m')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9222b0-e3ca-4d27-9e87-fb763f71f3b5",
   "metadata": {},
   "source": [
    "# Interactive BLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c798953e-094b-41f7-8647-c1db39d41279",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Num of observations:', len(lc_collection))\n",
    "print('Observation elapsed time:', lc_collection.time.max()  - lc_collection.time.min())\n",
    "\n",
    "# use the interactive transit period detection\n",
    "#   caveat: un-sure if combining observations over time make sense for the algorithm\n",
    "lc_collection.interact_bls()\n",
    "\n",
    "# if False: \n",
    "if False: \n",
    "    x_min = 1\n",
    "    x_max = 20\n",
    "    # Box Least Square assumes U-shaped transit model (rapid dips)\n",
    "    pdg_bls = lc_collection.remove_nans().to_periodogram(method='bls')\n",
    "    print('BLS')\n",
    "    pdg_bls.show_properties()\n",
    "    ax = pdg_bls.plot()\n",
    "    ax.set_title('BLS Periodogram, in period')\n",
    "    ax.set_xlim(x_min, x_max)\n",
    "\n",
    "    # Lomb Scargle better for general vairable curves with sin-like shape (gradual flucutation)\n",
    "    pdg_ls = lc_collection.remove_nans().to_periodogram(method='lombscargle')\n",
    "    print('Lomb Scargle')\n",
    "    pdg_ls.show_properties()\n",
    "    ax = pdg_ls.plot(view='period')\n",
    "    ax.set_title('Lomb Scargle Periodogram, in period')    \n",
    "    ax.set_xlim(x_min, x_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c79a0e-ee26-4131-b9cd-0039bf794426",
   "metadata": {},
   "source": [
    "# BLS - manual method - slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3a4157-c9eb-4acc-b61e-2290be06e9a7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# you don't have to change the code in this cell, but you do have to run it once for the rest of the notebook to work\n",
    "def plot_bls(alltime, allflux, alltimebinned, allfluxbinned, model, results, period, duration, t0, mid_transit_t0, in_transit = [0], in_transit_notbinned = [0]):\n",
    "    '''\n",
    "    Plot the BLS. This functinon is called in data_bls().\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    alltime  :  list\n",
    "        times (not binned)\n",
    "    allflux  :  list\n",
    "        normalized flux (not binned)\n",
    "    alltimebinned  :  list\n",
    "        binned time\n",
    "    allfluxbinned  :  list\n",
    "        normalized binned flux\n",
    "    model :  float\n",
    "        the transit model at the given period, duration, and phase\n",
    "    results :  class\n",
    "        results from the BLS fitting routine\n",
    "    period :  float\n",
    "        the period of the 'most-likely' transits\n",
    "    duration :  float\n",
    "        the duration of the transit\n",
    "    t0  :  float\n",
    "        the mid-transit time of the reference transit\n",
    "    in_transit = [0] :  float\n",
    "        if this is [0] (by deafult), the code knows that this is the initial run i.e. no transits have been removes (+ results are plotted in different colors)\n",
    "    in_transit_notbinned = [0]. :  float\n",
    "        if this is [0] (by deafult), the code knows that this is the initial run i.e. no transits have been removes (+ results are plotted in different colors)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        Plot the results from the BLS with three pannels: periodgram, best fit model to the transits, phase folded fit.\n",
    "    '''\n",
    "\n",
    "    if len(in_transit) == 1:  # conditions for the first 'round' of plotting\n",
    "        # define the colours of the plot\n",
    "        color1 = '#DC143C'\n",
    "        color2 = 'darkorange'\n",
    "        title = 'Initial BLS'\n",
    "\n",
    "    else:  # conditions for the second 'round' of plotting once the first event has been removed\n",
    "        # define the colours of the plot\n",
    "        color1 = 'deepskyblue'\n",
    "        color2 = '#4682B4'\n",
    "        title = 'Initial event removed'\n",
    "        \n",
    "\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(10, 14))\n",
    "\n",
    "    # highlight the harmonics of the peak period\n",
    "    ax = axes[0]\n",
    "    ax.axvline(period, alpha=0.4, lw=5, color = color1)\n",
    "    for n in range(2, 15):\n",
    "        ax.axvline(n*period, alpha=0.4, lw=2, linestyle=\"dashed\", color = color2) # plot the harmonics\n",
    "        ax.axvline(period / n, alpha=0.4, lw=2, linestyle=\"dashed\", color = color2)\n",
    "\n",
    "    # ------------\n",
    "    # plot the periodogram\n",
    "    ax.plot(results.period, results.power, \"k\", lw=0.5, label = 'P = %.3f T0 = %.3f' % (period,mid_transit_t0))\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlim(results.period.min(), results.period.max())\n",
    "    ax.set_xlabel(\"period (days)\")\n",
    "    ax.set_ylabel(\"log likelihood\")\n",
    "    ax.legend(fontsize = 10, loc = 1)\n",
    "\n",
    "    # ------------\n",
    "    # plot the light curve and best-fit model\n",
    "    ax = axes[1]\n",
    "\n",
    "    if len(in_transit) == 1:  # for the initial run\n",
    "        ax.plot(alltime, allflux, marker =\".\", alpha = 0.4, color = color2, ms=2, lw = 0, markerfacecolor = 'none')\n",
    "        ax.plot(alltimebinned, allfluxbinned, marker =\"o\", alpha = 0.6, color = 'black', ms=3, lw = 0, markerfacecolor = 'none')\n",
    "    else:  # for the second run (once the first 'event' has been removed)\n",
    "        ax.plot(alltime[~in_transit_notbinned], allflux[~in_transit_notbinned], marker =\".\", alpha = 0.4, color = color2, ms=2, lw = 0, markerfacecolor = 'none')\n",
    "        ax.plot(alltimebinned[~in_transit], allfluxbinned[~in_transit], marker =\"o\", alpha = 0.6, color = 'black',  markerfacecolor = 'none', ms=3, lw = 0)\n",
    "\n",
    "    x = np.linspace(alltimebinned.min(), alltimebinned.max(), 3*len(alltimebinned))\n",
    "    f = model.model(x, period, duration, t0)\n",
    "    ax.plot(x, f, lw=2, color = color1)\n",
    "    ax.set_xlim(alltimebinned.min(), alltimebinned.max())\n",
    "    ax.set_xlabel(\"time (days)\")\n",
    "    ax.set_ylabel(\"de-trended flux (ppt)\");\n",
    "\n",
    "    # ------------\n",
    "    ax = axes[2]\n",
    "    if len(in_transit) == 1:  # for the initial run\n",
    "        x_binned = (alltimebinned - t0 + 0.5*period) % period - 0.5*period\n",
    "        x = (alltime - t0 + 0.5*period) % period - 0.5*period\n",
    "    else: # for the second run (once the first 'event' has been removed)\n",
    "        x_binned = (alltimebinned[~in_transit] - t0 + 0.5*period) % period - 0.5*period\n",
    "        x = (alltime[~in_transit_notbinned] - t0 + 0.5*period) % period - 0.5*period\n",
    "\n",
    "    m_binned = np.abs(x_binned) < 0.5\n",
    "    m = np.abs(x) < 0.5\n",
    "\n",
    "    # plot the data\n",
    "    if len(in_transit) == 1:  # for the initial run\n",
    "        ax.plot(x[m], allflux[m],marker =\".\", alpha = 0.4, color = color2, ms=2, lw = 0, markerfacecolor = 'none')\n",
    "        ax.plot(x_binned[m_binned], allfluxbinned[m_binned], marker =\"o\", alpha = 0.6, color = 'black', ms=3, lw = 0, markerfacecolor = 'none')\n",
    "\n",
    "    else: # for the second run (once the first 'event' has been removed)\n",
    "        ax.plot(x[m], allflux[~in_transit_notbinned][m],marker =\".\", alpha = 0.4, color = color2, ms=2, lw = 0, markerfacecolor = 'none')\n",
    "        ax.plot(x_binned[m_binned], allfluxbinned[~in_transit][m_binned], marker =\"o\", alpha = 0.6, color = 'black', ms=3, lw = 0, markerfacecolor = 'none')\n",
    "\n",
    "    x = np.linspace(-0.5, 0.5, 1000)\n",
    "    f = model.model(x + t0, period, duration, t0)\n",
    "    ax.plot(x, f, lw=2, color = color1)\n",
    "    ax.set_xlim(-0.5, 0.5)\n",
    "    ax.set_xlabel(\"time since transit (days)\")\n",
    "    ax.set_ylabel(\"de-trended flux (ppt)\");\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd2806d-9f41-465c-a133-3811d638ac41",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# you don't have to change the code in this cell, but you do have to run it once for the rest of the notebook to work\n",
    "def data_bls(lc):\n",
    "    '''\n",
    "    function that runs the BLS routine and plots the results. The BLS is run twice and in the second\n",
    "    the most significant result found in the first run is removed.\n",
    "    Prior to running the BLS the data is detrended.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lc: from lightkurve for one or more sectors \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        two lists of the statistics of the to BLS runs. Each list contains:\n",
    "    stats_period\n",
    "    stats_t0\n",
    "    stats_depth\n",
    "    stats_depth_phased\n",
    "    stats_depth_half\n",
    "    stats_depth_odd\n",
    "    stats_depth_even\n",
    "    '''\n",
    "    \n",
    "    # normalize the data\n",
    "    try:\n",
    "        lc = lc.normalize()\n",
    "    except:\n",
    "        lc = lc.stitch()\n",
    "        \n",
    "    alltime = lc.time.value\n",
    "    allflux = lc.flux.value\n",
    "    \n",
    "    lc_bin = lc.bin(15/60/24) # you can change the binning factor here if you like\n",
    "    alltimebinned = lc_bin.time.value\n",
    "    allfluxbinned = lc_bin.flux.value\n",
    "        \n",
    "    # make sure that there are no nan (empty) values in the data - they cause everything to crash so let's get rid of them\n",
    "    mask_binned = np.isfinite(alltimebinned) * np.isfinite(allfluxbinned)\n",
    "    mask = np.isfinite(alltime) * np.isfinite(allflux)\n",
    "\n",
    "    alltimebinned = np.array(alltimebinned)[mask_binned]\n",
    "    allfluxbinned = np.array(allfluxbinned)[mask_binned]\n",
    "    alltime = np.array(alltime)[mask]\n",
    "    allflux = np.array(allflux)[mask]\n",
    "\n",
    "    # -------------------\n",
    "\n",
    "    # detrend the data before running the BLS\n",
    "\n",
    "    mask_binned = np.isfinite(alltimebinned) * np.isfinite(allfluxbinned)\n",
    "    alltimebinned = np.array(alltimebinned)[mask_binned]\n",
    "    allfluxbinned = np.array(allfluxbinned)[mask_binned]\n",
    "    # -----------------------\n",
    "\n",
    "    durations = np.linspace(0.05, 0.5, 15) # ????? CHECK THESE\n",
    "    periods = np.arange(0.7, (np.nanmax(alltimebinned) - np.nanmin(alltimebinned)), 0.01)\n",
    "    \n",
    "    model = BoxLeastSquares(alltimebinned, allfluxbinned)\n",
    "    results = model.power(periods, durations)\n",
    "\n",
    "    index = np.argmax(results.power)\n",
    "    period = results.period[index]\n",
    "    t0 = results.transit_time[index]\n",
    "    duration = results.duration[index]\n",
    "    mid_transit_t0 = model.compute_stats(period, duration, t0)['transit_times'][0]\n",
    "\n",
    "    # call the first round of plotting\n",
    "\n",
    "    plot_bls(alltime, allflux, alltimebinned, allfluxbinned, model, results, period, duration, t0, mid_transit_t0)\n",
    "\n",
    "    stats_period = period\n",
    "    stats_t0 = mid_transit_t0\n",
    "    stats_depth = model.compute_stats(period, duration, t0)['depth']\n",
    "    stats_depth_phased = model.compute_stats(period, duration, t0)['depth_phased']\n",
    "    stats_depth_half = model.compute_stats(period, duration, t0)['depth_half']\n",
    "    stats_depth_odd = model.compute_stats(period, duration, t0)['depth_odd']\n",
    "    stats_depth_even = model.compute_stats(period, duration, t0)['depth_even']\n",
    "\n",
    "    if (1*duration) >= period: # if the 'found' events are very short period, don't rn the BLS twice as the code would crash.\n",
    "        return [stats_period, stats_t0, stats_depth, stats_depth_phased, stats_depth_half, stats_depth_odd, stats_depth_even], [-999]\n",
    "\n",
    "    # Find the in-transit points using a longer duration as a buffer to avoid ingress and egress\n",
    "    in_transit = model.transit_mask(alltimebinned, period, 2*duration, t0)\n",
    "    in_transit_notbinned = model.transit_mask(alltime, period, 2*duration, t0)\n",
    "    \n",
    "    # Re-run the algorithm, and plot the results\n",
    "    model2 = BoxLeastSquares(alltimebinned[~in_transit], allfluxbinned[~in_transit])\n",
    "    results2 = model2.power(periods, durations)\n",
    "\n",
    "    # Extract the parameters of the best-fit model\n",
    "    index = np.argmax(results2.power)\n",
    "    period2 = results2.period[index]\n",
    "    t02 = results2.transit_time[index]\n",
    "    duration2 = results2.duration[index]\n",
    "    mid_transit_t02 = model.compute_stats(period2, duration2, t02)['transit_times'][0]\n",
    "    \n",
    "    # call the second round of plotting - once the intitial transit has been removed\n",
    "    plot_bls(alltime, allflux, alltimebinned, allfluxbinned, model2, results2,period2,duration2,t02, mid_transit_t02, in_transit = in_transit, in_transit_notbinned = in_transit_notbinned)\n",
    "    \n",
    "    stats2_period = period2\n",
    "    stats2_t0 = mid_transit_t02\n",
    "    stats2_depth = model2.compute_stats(period2, duration2, t0)['depth']\n",
    "    stats2_depth_phased = model2.compute_stats(period2, duration2, t0)['depth_phased']\n",
    "    stats2_depth_half = model2.compute_stats(period2, duration2, t0)['depth_half']\n",
    "    stats2_depth_odd = model2.compute_stats(period2, duration2, t0)['depth_odd']\n",
    "    stats2_depth_even = model2.compute_stats(period2, duration2, t0)['depth_even']\n",
    "        \n",
    "    df = pd.DataFrame({\"Period (days)\": [stats_period,stats2_period], \"T0 (TBJD)\":[stats_t0,stats2_t0], \"Transit depth (ppm)\":[stats_depth[0],stats2_depth[0]], \"Odd depth (ppm)\": [stats_depth_odd[0],stats2_depth_odd[0]], \"Even depth (ppm)\":[stats_depth_even[0],stats2_depth_even[0]]})\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7a269f-3d82-42c6-8a4c-c7f825c6e8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the above functions with this simple command here (once you have downloaded the data - defined as lc here)\n",
    "# This cell can take a minute or so to run (it's doing a lot of work)\n",
    "\n",
    "df = data_bls(lc_coll)\n",
    "\n",
    "print (\"Some statistics about the two fits (these numbers are just estimates and should be taken with a large pinch of salt!)\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7599252e-e0b0-4ad3-8dd9-8344ea9e79d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Colour graded scatter plot for use later when folding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c126523-dc78-48ba-ba8b-c9b914ff2235",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot the data to look at when the transit events are\n",
    "# this plotting is different to how we did it previously as I wanted to plot the data points coloured by time (earlier times are darker)\n",
    "plt.style.use('default')\n",
    "fig, ax = plt.subplots(figsize=(20,6))\n",
    "\n",
    "plt.scatter(lc_collection.time.value, lc_collection.flux.value, c = lc_collection.time.value, s = 1, cmap = 'tab20b')\n",
    "\n",
    "plt.xlabel(\"Time (BJD - 2457000)\")\n",
    "plt.ylabel(\"Normalized Flux\")\n",
    "# Reset the max and min\n",
    "plt.ylim(ymin, ymax)\n",
    "plt.title(TIC_no)\n",
    "plt.show()\n",
    "print(\"Suggested period = {}\".format(starting_period))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d30b22f-e4e9-4583-b010-ca860f011cbd",
   "metadata": {},
   "source": [
    "# Interactive plot to refine the period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3279cd89-d0f7-4f72-99c2-3ebbc8ea5ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "In the code below you can change the period using a slider and watch how different orbital periods affect the phase folded lightcurve. if you click on the slider, you can use the arrows on the keypad to move it by smaller amounts. NOTE: there is often a bit of a lag between changing the value and the figure updating!\n",
    "\n",
    "Run the interactive widget using this line of code (see example below):\n",
    "\n",
    "*interact(plot_phase_folded_color, period = widgets.FloatSlider(**value**=xx,**min**=xx,**max**=xx,**step**=xx,description='period:', readout_format='.4f'))*\n",
    "\n",
    "The values in bold need to be changed for different targets!\n",
    "- **value**: starting guess at the period\n",
    "- **min**: the minimum period that you think it could be\n",
    "- **max**: the maximum period that you think it could be\n",
    "- **step**: the step size that the widget jumps when you press the up or down arrow on your keyboard (good starting point=0.0001 - if you see no change in the phase folded lighcurve when you press the up and down errors then make the step sizelarger!)\n",
    "\n",
    "In order to use this widget, you need to give it a range of periods that you want to test (so you already need an idea of the period!). \n",
    "'''\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def plot_phase_folded_color(period, xrange=1):\n",
    "\n",
    "    # phase fold the light curve\n",
    "    lc_phased = lc_collection.fold(period = period, epoch_time = transit_time[0])\n",
    "    \n",
    "    # plot the binned and unbinned phase folded lightcurve on the same figure\n",
    "    %matplotlib inline \n",
    "    fig, ax = plt.subplots(figsize = (30,12))\n",
    "    \n",
    "    plt.scatter(lc_phased.time.value, lc_phased.flux.value, c = lc_phased.time_original.value, s = 4, marker = 'o', cmap = 'tab20b')\n",
    "\n",
    "    # if you prefer all the point to have the same color, delete the line above and get rid of the hastag in fron of the line below\n",
    "    #lc_phased.plot(ax = ax, marker = '.', linewidth = 0, color = 'black', alpha = 0.2, markersize = 3)\n",
    "    \n",
    "    plt.xlabel(\"Phase\")\n",
    "    plt.ylabel(\"Normalized flux\")\n",
    "    #plt.ylim(ymin, ymax)\n",
    "    xlims = xrange\n",
    "    plt.xlim(-xlims,xlims)\n",
    "    #plt.ylim(0.97, 1.03)\n",
    "    plt.show()\n",
    "    \n",
    "start_p = widgets.Text(\n",
    "       value=str(starting_period),\n",
    "       description='Period', )\n",
    "start_r = widgets.Text(\n",
    "       value=str(0.2),\n",
    "       description='Slider Range:', )\n",
    "start_step = widgets.Text(\n",
    "       value=str(0.0001),\n",
    "       description='Slider Step:', )\n",
    "start_x = widgets.Text(\n",
    "       value=str(int(starting_period/2)+1),\n",
    "       description='Xrange', )\n",
    "\n",
    "button_plot = widgets.Button(description='Plot', button_style='primary')\n",
    "out_plot = widgets.Output()\n",
    "def on_plot_button_clicked(_):\n",
    "\n",
    "    with out_plot:\n",
    "        clear_output()\n",
    "        #========= Set Starting Period and slider range ===============\n",
    "        starting_period=float(start_p.value)\n",
    "        starting_range=float(start_r.value)\n",
    "        step = float(start_step.value)\n",
    "        #=========Set X range starting value =============================================\n",
    "        xrange_start = float(start_x.value)\n",
    "        #=================================================================================\n",
    "        interact(plot_phase_folded_color, period = widgets.FloatSlider(value=starting_period,min =starting_period-starting_range,max=starting_period+starting_range,step=step,description='period:', readout_format='.5f'), xrange = widgets.FloatSlider(value=xrange_start,min =0,max=(starting_period/2)+1,step=0.05,description='xrange:'))     \n",
    "# linking button and function together using a button's method\n",
    "button_plot.on_click(on_plot_button_clicked)        \n",
    "\n",
    "box3 = widgets.VBox([start_p,start_r,start_step,start_x,button_plot,out_plot ])\n",
    "box3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9be641c-6d36-4732-914e-9bd2ebe1ea20",
   "metadata": {},
   "source": [
    "# Plot again to enable measurements to be taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc2e76a-f581-43dc-84a6-09702de79d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================= look at the period selected above and copy and paste it here =====================\n",
    "period = 1.703583731306844\n",
    "offset = 0\n",
    "# =============================================================================================================\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "printmd(\"**Right-click the six parameters of the dip** -  1: Start   2: End    3: Start of floor    4: End of floor    5: Top    6: Bottom\")\n",
    "\n",
    "# phase fold the light curve using this period and the time of one of the above transit as the value of t0 \n",
    "lc_phased = lc_collection.fold(period = period, epoch_time = transit_time[0], epoch_phase=offset)\n",
    "lc_phased_binned = lc_phased.bin(10/24/60)\n",
    "\n",
    "# This is a manual alternative to the slider above if needed\n",
    "#fig, ax = plt.subplots(figsize = (20,8))\n",
    "#lc_phased.plot(ax = ax, marker = '.', linewidth = 0, color = 'blue', alpha = 0.2, markersize = 3)\n",
    "#plt.xlim(-.5,.5)\n",
    "#plt.ylim(.80,1.1)\n",
    "# change the period above and re run this cell until the transit events below line up\n",
    "\n",
    "# Odd/Even plot to look for possible different planets or EB, along with binned overlay to help with measurements\n",
    "%matplotlib widget\n",
    "plt.style.use('default')\n",
    "fig, ax = plt.subplots(figsize=(16,8))\n",
    "lc_phased[lc_phased.odd_mask].plot(ax=ax, linewidth=0,marker='.', color='red',alpha=0.2,markersize=5,label='unbinned_odd')\n",
    "lc_phased[lc_phased.even_mask].plot(ax=ax, linewidth=0,marker='.', color='blue',alpha=0.2,markersize=5,label='unbinned_even')\n",
    "lc_phased_binned.plot(ax=ax, linewidth=0,marker='o', color='black',markersize=3,alpha=0.8,label='binned')\n",
    "\n",
    "xlims =70\n",
    "plt.xlim(-xlims,xlims)\n",
    "focus_factor = 1 #  Set higher to focus the y dimension\n",
    "plt.ylim(fluxmin+(fluxmax-1)*focus_factor, fluxmax-(fluxmax-1)*focus_factor)\n",
    "#plt.ylim(0.995,1.005)\n",
    "plt.ylim(ymin, ymax)\n",
    "ax.set(title=TIC)\n",
    "plt.show()\n",
    "\n",
    "# Click event to select all 6 parameter one after the other with right click.  \n",
    "def onclick(event):\n",
    "    global ix, iy, coords, tran\n",
    "    ix, iy = event.xdata, event.ydata\n",
    "    if event.button == 3:  # right click\n",
    "\n",
    "        if len(coords) < 2:\n",
    "            coords.append((ix, iy))\n",
    "            tran.append(plt.axvline(ix, color = 'blue', zorder = -1))   \n",
    "        elif len(coords) < 4:\n",
    "            coords.append((ix, iy))\n",
    "            tran.append(plt.axvline(ix, color = 'grey', linestyle = '-', zorder = -1))            \n",
    "        elif len(coords) < 6:\n",
    "            coords.append((ix, iy))\n",
    "            tran.append(plt.axhline(iy, color = 'green', zorder = -1))            \n",
    "        elif len(coords) == 6:\n",
    "            #fig.canvas.mpl_disconnect(cid)\n",
    "            for line in tran:\n",
    "                try: \n",
    "                    line.remove()\n",
    "                except:\n",
    "                    pass\n",
    "            tran.clear()   \n",
    "            coords.clear()\n",
    "\n",
    "# Initialise the arrays before we start\n",
    "coords = []\n",
    "tran = []\n",
    "\n",
    "cid = fig.canvas.mpl_connect('button_press_event', onclick)  # Connect the event\n",
    "\n",
    "button_reset = widgets.Button(description='Reset', button_style='warning')\n",
    "\n",
    "out_op = widgets.Output()\n",
    "def on_reset_button_clicked(_):\n",
    "    global coords, tran\n",
    "    with out_op:\n",
    "        clear_output()\n",
    "        for line in tran:\n",
    "            try: \n",
    "                line.remove()\n",
    "            except:\n",
    "                pass\n",
    "        tran.clear()   \n",
    "        coords.clear()\n",
    "# linking button and function together using a button's method\n",
    "button_reset.on_click(on_reset_button_clicked)        \n",
    "\n",
    "button_op = widgets.Button(description='Done', button_style='primary')\n",
    "def on_op_button_clicked(_):\n",
    "    global coords\n",
    "    global transit_depth,transit_start,transit_end,transit_length,transit_mid,floor_length\n",
    "    with out_op:\n",
    "        clear_output()\n",
    "        if len(coords) < 6:\n",
    "            print(\"Select the six parameters before continuing\")\n",
    "        else:\n",
    "            #fig.canvas.mpl_disconnect(cid)\n",
    "            transit_top = coords[4][1] \n",
    "            transit_bottom = coords[5][1] \n",
    "            transit_depth = transit_top-transit_bottom\n",
    "            if transit_depth < 0 : transit_depth *= -1  # In case we choose the wrong way round\n",
    "            print(\"Depth = %6.4f\" %transit_depth)\n",
    "            transit_start = coords[0][0] \n",
    "            transit_end = coords[1][0] \n",
    "            transit_length = (transit_end-transit_start) * 24\n",
    "            if transit_length < 0 : transit_length *= -1  # In case we choose the wrong way round\n",
    "            transit_mid = transit_start+(transit_end-transit_start)/2\n",
    "            print('Mid-point = %6.4f' %transit_mid)\n",
    "            print('Duration = %6.4f hours' %transit_length)\n",
    "            floor_start = coords[2][0] \n",
    "            floor_end = coords[3][0] \n",
    "            floor_length = (floor_end-floor_start) * 24\n",
    "            if floor_length < 0 : floor_length *= -1  # In case we choose the wrong way round\n",
    "            print(\"Floor = %6.4f hours\" %floor_length)         \n",
    "# linking button and function together using a button's method\n",
    "button_op.on_click(on_op_button_clicked)        \n",
    "boxop = widgets.VBox([button_reset,button_op,out_op ])\n",
    "boxop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76c5a81-6e3c-410e-8099-ea8236996466",
   "metadata": {},
   "source": [
    "# Planet Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20674417-0b9e-4276-bf1e-07c90f987cd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import star_data as star\n",
    "GAIA_ID = TIC_rad = TIC_erad = TIC_mass = TIC_emass = TIC_Teff = TIC_eTeff = TIC_lum = TIC_Vmag = TIC_dist = TIC_mind = TIC_maxd = TIC_ra = TIC_dec = float('nan')\n",
    "GAIA_ID, TIC_rad, TIC_erad, TIC_mass, TIC_emass, TIC_Teff, TIC_eTeff, TIC_lum, TIC_Vmag, TIC_dist, TIC_mind, TIC_maxd, TIC_ra, TIC_dec = star.get_exofop_data(TIC_no)\n",
    "R_star = float(TIC_rad)\n",
    "M_star = float(TIC_mass)\n",
    "star.get_simbad_and_EB_data(TIC_no)\n",
    "\n",
    "try:\n",
    "    gaia_rad = gaia_rad_lower = gaia_rad_upper = gaia_rad_sigma = gaia_teff = gaia_teff_lower = gaia_teff_upper = gaia_teff_sigma = gaia_lum = gaia_lum_lower = gaia_lum_upper = gaia_mass = gaia_mass_lower = gaia_mass_upper = gaia_mass_sigma = float('nan')\n",
    "    gaia_rad, gaia_rad_lower, gaia_rad_upper, gaia_rad_sigma, gaia_teff, gaia_teff_lower, gaia_teff_upper, gaia_teff_sigma, gaia_lum, gaia_lum_lower, gaia_lum_upper, gaia_mass, gaia_mass_lower, gaia_mass_upper, gaia_mass_sigma = star.get_gaia_data(GAIA_ID)\n",
    "    if not(np.isnan(gaia_rad)):\n",
    "        R_star= float(gaia_rad)\n",
    "    if not(np.isnan(gaia_mass)):    \n",
    "        M_star = float(gaia_mass)\n",
    "except:\n",
    "    print(\"Unable to get all GAIA data\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738c79a3-7449-4351-83b1-0437a518a9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============= Radius relative to sol ========================\n",
    "#TIC_rad = 0.761  # Override radius\n",
    "#R_star = float(TIC_rad)\n",
    "#R_star= float(gaia_rad)\n",
    "# =============================================================\n",
    "Rs = R_star * u.Rsun\n",
    "r_pl_solar_radius = np.sqrt(transit_depth) * Rs\n",
    "Rs_km = Rs.to(u.kilometer)\n",
    "r_pl_solar_radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f000ab70-b54f-4d81-bdcc-d8f82bc60909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Radius relative to earth\n",
    "r_pl_earth_radius = r_pl_solar_radius.to(u.Rearth)\n",
    "r_pl_earth_radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eed16d-837f-445e-b891-7f04c84daa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Radius relative to jupiter\n",
    "r_pl_jup_radius = r_pl_solar_radius.to(u.Rjupiter)\n",
    "r_pl_jup_radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daa5b04-0c74-4a9b-a3ec-aea1a578a29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Radius in kilometers\n",
    "r_pl_km_radius = r_pl_solar_radius.to(u.kilometer)\n",
    "r_pl_km_radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0711d4-fc6e-422b-be51-9dde44af9529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ Mass of star relative to sol ==================\n",
    "#TIC_mass = 0.820    # Override masses\n",
    "#M_star = float(TIC_mass)\n",
    "#M_star = float(gaia_mass)\n",
    "# ============================================================\n",
    "transit_length_days = transit_length/24\n",
    "floor_length_days = floor_length/24\n",
    "\n",
    "# Impact Parameter\n",
    "import math\n",
    "sqdf = math.sqrt(transit_depth)\n",
    "ts = (floor_length**2)/(transit_length**2)\n",
    "\n",
    "#bs = math.sqrt((((1-sqdf)*(1-sqdf))-(ts*(1+sqdf)*(1+sqdf)))/(1.0-ts))\n",
    "bs = math.sqrt(((1-sqdf)**2-(ts*(1+sqdf)**2))/(1-ts))\n",
    "\n",
    "# A/r*\n",
    "ar = (2 * period * math.pow(transit_depth,0.25))/(math.pi * math.sqrt((transit_length_days**2)-(floor_length_days**2)));\n",
    "\n",
    "# Tc\n",
    "tc = transit_length/math.sqrt(1-(bs**2));\n",
    "\n",
    "# Separation\n",
    "pp = period/365;\n",
    "au = math.pow(pp*pp*M_star,0.333);\n",
    "au_km = (au * u.AU).to(u.kilometer)\n",
    "i = math.degrees(math.acos((bs*Rs_km)/au_km))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0723b792-f886-40d4-9168-5ffd4bf1fb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from astropy import units as u\n",
    "Ms = M_star * u.Msun\n",
    "Ms_g = Ms.to(u.gram)\n",
    "print(Ms_g)\n",
    "Rs = R_star * u.Rsun\n",
    "Rs_cm = Rs.to(u.centimeter)\n",
    "print(Rs_cm)\n",
    "rho = Ms_g.value/((4/3)*math.pi*math.pow(Rs_cm.value,3))\n",
    "print(rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7052d346-0ea6-4981-976b-3398216f8b56",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "print ('\\033[1mSummary\\033[0m: ' + TIC)    \n",
    "print ('T0 = %8.4f BJD' %transit_time[0])\n",
    "print ('Transit_Depth = %6.4f' %(transit_depth))\n",
    "print ('Transit_Length = %6.4f hours' %(transit_length))\n",
    "print ('Floor_Length = %6.4f hours' %(floor_length))\n",
    "print ('Star_Radius = ' + f\"{R_star:0.04f} Rsol\")\n",
    "print ('Star_Mass = ' + f\"{M_star:0.04f} Msol\")\n",
    "print ('Star_Density = %6.4f g/cm^3' %(rho))\n",
    "print ('Vmag = %7.4f  GAIA = %d' %(TIC_Vmag, GAIA_ID))\n",
    "print ('Distance = %8.4f (-%0.4f +%0.4f)pc' %(TIC_dist, TIC_mind, TIC_maxd))\n",
    "print ('Planet_Radius = ' + f\"{r_pl_jup_radius:0.02f}\" + \"   \" + f\"{r_pl_earth_radius:0.02f}\")   \n",
    "print ('Period = %7.4f days' %(period))\n",
    "print ('Impact_Parameter = %5.4f' %bs)\n",
    "print ('i = %6.4f deg' %i)\n",
    "print ('A/rstar = %6.4f' %ar)\n",
    "print ('Transit_Central = %6.4f hours (est.)' %tc)\n",
    "print ('Separation = %6.4f AU' %au)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6faf8a-818e-47e0-aa39-9ebd7759c1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate period from transit parameters\n",
    "# Separation\n",
    "tcm = (tc/(13 * R_star))*math.sqrt(M_star)  #Using solar units and relative to transit time of earth - 13 hours\n",
    "au = tcm ** 2\n",
    "calc_period = math.sqrt((au*au*au)/M_star)*365  #Keplers 3rd law - x365 to get period in days rather than earth years\n",
    "\n",
    "# A/r*\n",
    "ar = (2 * period * math.pow(transit_depth,0.25))/(math.pi * math.sqrt((transit_length_days**2)-(floor_length_days**2)))\n",
    "\n",
    "print ('A/r* = %6.4f' %ar)\n",
    "print ('Period = %7.4f days' %(calc_period))\n",
    "print ('Separation = %6.4f AU' %au)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0968091d-5e5e-4fb5-9ffd-804a00890395",
   "metadata": {},
   "source": [
    "# Export files for Pyaneti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187b6231-8b94-4ad0-9cd0-60a04103414b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(\"Exofop data\")\n",
    "    print(\"Radius = {}\".format(*TIC_rad))\n",
    "    print(\"Mass = {}\".format(*TIC_mass))\n",
    "    print(\"Teff = {}\".format(*TIC_Teff))\n",
    "    print(\"GAIA data\")\n",
    "    print(\"Radius = {}\".format(*gaia_rad))\n",
    "    print(\"Mass = {}\".format(*gaia_mass))\n",
    "    print(\"Teff = {}\".format(*gaia_Teff))\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98b9c23-eae1-4be1-87ec-48995cc5e0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output\n",
    "chk_exofop = widgets.Checkbox(\n",
    "           value=False,\n",
    "           description='Use exofop:',)\n",
    "menu_method = widgets.Dropdown(\n",
    "       options=['DETREND', 'CUTOUT', '30MIN'],\n",
    "       value='DETREND',\n",
    "       description='Method:')\n",
    "chk_density = widgets.Checkbox(\n",
    "           value=False,\n",
    "           description='Fit density:',)\n",
    "suffix = widgets.Text(\n",
    "       value='_a_fit',\n",
    "       description='Suffix:', )\n",
    "\n",
    "button_set = widgets.Button(description='Set Options', button_style='primary')\n",
    "out_set = widgets.Output()\n",
    "def on_set_button_clicked(_):\n",
    "    global use_exofop\n",
    "    global data_method\n",
    "    global fit_density\n",
    "    global model_suffix\n",
    "    with out_set:\n",
    "        clear_output()\n",
    "        use_exofop = chk_exofop.value\n",
    "        data_method = menu_method.value\n",
    "        fit_density = chk_density.value\n",
    "        model_suffix = suffix.value\n",
    "        if use_exofop == True:\n",
    "            print(\"Using exofop data\")\n",
    "        else:\n",
    "            print(\"Using GAIA data\")\n",
    "        print(\"Data method: {}\".format(data_method))\n",
    "        if fit_density == True:\n",
    "            print(\"Fitting density\")\n",
    "        else:\n",
    "            print(\"Fitting semi-major axis\")        \n",
    "        print(\"File suffix: {}\".format(model_suffix))\n",
    "        \n",
    "# linking button and function together using a button's method\n",
    "button_set.on_click(on_set_button_clicked)    \n",
    "\n",
    "box4 = widgets.VBox([chk_exofop,menu_method,chk_density,suffix,button_set,out_set])\n",
    "box4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f49db29-0f6a-4fb3-b679-8a609e6c0086",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import astropy.io.fits as pf\n",
    "\n",
    "def detrend_pyaneti(tic, transit_time_list, alltime, allflux, allflux_err, lim_window, lim, poly_n, save = True):\n",
    "    \n",
    "    global LC_max\n",
    "    combined_corr_time = []\n",
    "    combined_corr_flux = []\n",
    "    combined_corr_err  = []\n",
    "    \n",
    "    for transit_time in transit_time_list:\n",
    "        try:\n",
    "\n",
    "            mask = (np.array(alltime) > transit_time-lim_window) & (np.array(alltime) < transit_time+lim_window)\n",
    "\n",
    "            masked_time= np.array(alltime)[mask]\n",
    "            masked_flux = np.array(allflux)[mask]\n",
    "            masked_flux_err = np.array(allflux_err)[mask]\n",
    "\n",
    "            np.nan_to_num(masked_time,False,nan=0.0)  # Make dure there are no Nans as it breaks polyfit\n",
    "            np.nan_to_num(masked_flux,False,nan=1.0)\n",
    "\n",
    "            z = np.polyfit(masked_time, masked_flux, 1)\n",
    "\n",
    "            p = np.poly1d(z)\n",
    "\n",
    "            xp = np.linspace(np.nanmin(masked_time), np.nanmax(masked_time), 100)\n",
    "\n",
    "            finite = np.isfinite(masked_time) & np.isfinite(masked_flux)\n",
    "            \n",
    "            x = masked_time[finite]\n",
    "            y = masked_flux[finite]\n",
    "            y_err = masked_flux_err[finite]\n",
    "                      \n",
    "            #plt.show()\n",
    "\n",
    "            oot = (x > (transit_time-lim)) & (x < (transit_time+lim))\n",
    "            \n",
    "            x_oot = x[~oot]\n",
    "            y_oot = y[~oot]\n",
    "            \n",
    "            # Detrend with a 2d order polynomial\n",
    "            \n",
    "            model = np.polyfit(x_oot, y_oot, poly_n)\n",
    "            predicted = np.polyval(model, x)\n",
    "            \n",
    "            fig, axes = plt.subplots(nrows=2, sharex=True, figsize=(10,10))\n",
    "            \n",
    "            axes[0].plot(x, y, '#c44e52', marker='o', lw =0)\n",
    "            axes[0].plot(x, predicted, 'k-')\n",
    "            axes[0].set(title='Original Data and 2nd Order Polynomial Trend')\n",
    "            axes[0].axvline(transit_time-lim)\n",
    "            axes[0].axvline(transit_time+lim)\n",
    "                            \n",
    "            axes[1].plot(x, y - predicted,  '#c44e52', marker='o', lw =0)\n",
    "            axes[1].set(title='Detrended Residual')\n",
    "            \n",
    "            combined_corr_time.append(x)\n",
    "            combined_corr_flux.append((y - predicted) + 1)\n",
    "            combined_corr_err.append(y_err)\n",
    "            \n",
    "            plt.show()\n",
    "        except Exception as e: print(e)\n",
    "            #print (\"{} not in the data set\".format(transit_time))\n",
    "\n",
    "    # Include the first and last data points so the model extends to the full time range\n",
    "    combined_corr_time.insert(0,alltime[0])\n",
    "    combined_corr_flux.insert(0,allflux[0])\n",
    "    combined_corr_err.insert(0,allflux_err[0])\n",
    "    combined_corr_time.append(alltime[len(alltime)-1])  \n",
    "    combined_corr_flux.append(allflux[len(allflux)-1])\n",
    "    combined_corr_err.append(allflux_err[len(allflux_err)-1])\n",
    "    \n",
    "    combined_corr_time = np.hstack(combined_corr_time)\n",
    "    combined_corr_flux = np.hstack(combined_corr_flux)\n",
    "    combined_corr_err  = np.hstack(combined_corr_err)\n",
    "    #print(combined_corr_time,combined_corr_flux,combined_corr_err)\n",
    "    finite_mask = np.isfinite(combined_corr_time) & np.isfinite(combined_corr_flux) & np.isfinite(combined_corr_err)\n",
    "\n",
    "    combined_corr_time = combined_corr_time[finite_mask] \n",
    "    combined_corr_flux =  combined_corr_flux[finite_mask]\n",
    "    combined_corr_err  = combined_corr_err[finite_mask]\n",
    "    \n",
    "    fig, axes = plt.subplots(figsize=(14,7))\n",
    "    axes.plot(combined_corr_time,combined_corr_flux, marker='o', lw =0)\n",
    "    plt.show()\n",
    "    \n",
    "    cadence_col = []\n",
    "    for ftime in enumerate(combined_corr_time):\n",
    "        if ftime[1] < LC_max:\n",
    "            cadence_col.append(\"LC\")\n",
    "        else:\n",
    "            cadence_col.append(\"SC\")     \n",
    "    \n",
    "    with open(pyaneti_data_file, \"w\", newline='') as f:\n",
    "        writer = csv.writer(f, delimiter='\\t')\n",
    "        writer.writerow(['#time', 'flux', 'flux_err', 'band'])    \n",
    "    \n",
    "    if save == True:\n",
    "        with open(pyaneti_data_file, \"a\", newline='') as f:\n",
    "            writer = csv.writer(f, delimiter='\\t')\n",
    "            writer.writerows(zip(combined_corr_time, combined_corr_flux, combined_corr_err,cadence_col))  # Comment out for full data        \n",
    "        \n",
    "        #np.savetxt(pyaneti_data_file, np.array([combined_corr_time, combined_corr_flux, combined_corr_err, cadence_col]).T)\n",
    "        print(\"Created detrended data file: \" + pyaneti_data_file)\n",
    "\n",
    "#  Set up data and options\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import shutil\n",
    "\n",
    "# Add Long cadence (LC) and short cadence (SC) column\n",
    "# LC_max is the highest time value of long cadence data used to separate the - set to 0 if all short cadence\n",
    "\n",
    "nbands = 1\n",
    "LC_max = 0\n",
    "if nbands > 1:\n",
    "    bands = \"bands = ['SC','LC']\\nt_cad = [2/24/60,30/24/60]\\nn_cad = [1,10]\\nis_multi_radius = False\"\n",
    "    is_jitter_tr = \"True\"\n",
    "else:\n",
    "    bands = \"n_cad = [1]\\nt_cad = [2/24/60]\"\n",
    "    #bands = \"n_cad = [1]\\nt_cad = [0.3/24/60]\"\n",
    "    is_jitter_tr = \"False\"\n",
    "    \n",
    "# *****************    \n",
    "\n",
    "if use_exofop:\n",
    "    pya_rad = TIC_rad\n",
    "    pya_erad = TIC_erad\n",
    "    pya_mass = TIC_mass\n",
    "    pya_emass = TIC_emass\n",
    "    pya_Teff = TIC_Teff\n",
    "    pya_eTeff = TIC_eTeff\n",
    "    radius_source = \"Exofop\"\n",
    "    mass_source = \"Exofop\"\n",
    "    Teff_source = \"Exofop\"\n",
    "else:\n",
    "    #GAIA data\n",
    "    pya_rad = gaia_rad\n",
    "    pya_erad = gaia_rad_sigma\n",
    "    radius_source = \"GAIA\"\n",
    "    if np.isnan(gaia_mass):\n",
    "        pya_mass = TIC_mass\n",
    "        mass_source = \"Exofop\"\n",
    "    else:\n",
    "        pya_mass = gaia_mass\n",
    "        mass_source = \"GAIA\"\n",
    "    if np.isnan(gaia_mass_sigma):\n",
    "        pya_emass = TIC_emass\n",
    "    else:\n",
    "        pya_emass = gaia_mass_sigma\n",
    "    if np.isnan(gaia_teff):\n",
    "        pya_Teff = TIC_Teff\n",
    "        Teff_source = \"Exofop\"\n",
    "    else:\n",
    "        pya_Teff = gaia_teff\n",
    "        Teff_source = \"GAIA\"\n",
    "    if np.isnan(gaia_teff_sigma):\n",
    "        pya_eTeff = TIC_eTeff\n",
    "    else:\n",
    "        pya_eTeff = gaia_teff_sigma\n",
    "    data_source = \"GAIA\"\n",
    "    \n",
    "if fit_density:\n",
    "    min_a = rho\n",
    "    max_a = rho*0.15\n",
    "    sample_stellar_density = \"True\"\n",
    "    fit_a = \"g\"\n",
    "    fit_a_comment = \"We fit a with gaussian priors (given by the stellar parameters)\"\n",
    "else:\n",
    "    min_a = 0.001\n",
    "    max_a = 200\n",
    "    sample_stellar_density = \"False\"\n",
    "    fit_a = \"u\"\n",
    "    fit_a_comment = \"We fit the scaled semi-major axis\"    \n",
    "# Pyaneti files\n",
    "\n",
    "#pyaneti_home_dir = r\"..\"  \n",
    "pyaneti_home_dir = \"/home/ian/pyaneti\"\n",
    "inpy_dir = pyaneti_home_dir + \"/inpy/\"\n",
    "outpy_dir = pyaneti_home_dir + \"/outpy/\"\n",
    "pyaneti_data_filename = '{}_data.txt'.format(TIC_no)\n",
    "pyaneti_data_file = inpy_dir + '{}/'.format(TIC_no) + pyaneti_data_filename  \n",
    "input_fit_filename = \"input_fit.py\"\n",
    "pyaneti_input_file = inpy_dir + '{}/{}'.format(TIC_no,input_fit_filename)\n",
    "pyaneti_command = 'python pyaneti.py {}'.format(TIC_no)\n",
    "target_out_dir = outpy_dir + '{}_out'.format(TIC_no)\n",
    "target_in_dir = inpy_dir + '{}'.format(TIC_no)\n",
    "pyaneti_full_data_file = target_out_dir + '/full_' + pyaneti_data_filename \n",
    "\n",
    "#remove any existing files first\n",
    "try:\n",
    "    shutil.rmtree(target_out_dir)\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    shutil.rmtree(target_in_dir)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Create directories to store the files\n",
    "path = inpy_dir + TIC_no\n",
    "try:\n",
    "    os.mkdir(path)\n",
    "except OSError:\n",
    "    pass   # Assume its already there\n",
    "\n",
    "path = target_out_dir\n",
    "try:\n",
    "    os.mkdir(path)\n",
    "except OSError:\n",
    "    pass   # Assume its already there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a61810-256a-487a-8540-cef474092d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this if flux_errs are NaNs in some of the data\n",
    "#lc_collection['flux_err'] = [0.0003 if math.isnan(x) else x for x in lc_collection['flux_err']]\n",
    "#lc_collection['flux_err'] = [0.003 if x<0.003 else x for x in lc_collection['flux_err']]\n",
    "#print(lc_collection['flux_err'])\n",
    "# All the data in Mito\n",
    "#import mitosheet\n",
    "#import pandas as pd\n",
    "#dat=pd.DataFrame(lc_collection['flux'])\n",
    "#mitosheet.sheet(dat)  #pass the data frame into mito\n",
    "#print(lc_collection['flux'].unit)\n",
    "#print(lc_collection['flux_err'].unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec929ed-45ad-49b0-9dc7-8b1426f934e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_method == \"CUTOUT\":  # Option to export just cutouts round the transit (no detrending)\n",
    "    # Data file - just the 2 days surrounding the dip (See below if full data file wanted - but it slows pyaneti down!)\n",
    "    lc_norm = lc_collection.normalize()\n",
    "    # Export file for pyaneti\n",
    "    with open(pyaneti_data_file, \"w\", newline='') as f:\n",
    "        writer = csv.writer(f, delimiter='\\t')\n",
    "        writer.writerow(['#time', 'flux', 'flux_err', 'band'])\n",
    "\n",
    "    alltime = lc_norm.remove_nans().time.btjd\n",
    "    allflux = lc_norm.remove_nans().flux\n",
    "    allfluxerr = lc_norm.remove_nans().flux_err\n",
    "\n",
    "    # If the transits are within two days of each other we will get overlaps, hopefully this mask will handle that!\n",
    "\n",
    "    pyaneti_mask = (alltime > (transit_time[0] - 1)) * (alltime < (transit_time[0] + 1)) \n",
    "\n",
    "    for i in range(1,len(transit_time)):\n",
    "        pyaneti_mask += (alltime > (transit_time[i] - 1)) * (alltime < (transit_time[i] + 1))\n",
    "        \n",
    "    # Include the first and last data points so the model extends to the full time range\n",
    "    pyaneti_mask[0] = True\n",
    "    pyaneti_mask[len(alltime)-1] = True\n",
    "    \n",
    "    cadence_col = []\n",
    "    for ftime in enumerate(alltime[pyaneti_mask]):\n",
    "        if ftime[1] < LC_max:\n",
    "            cadence_col.append(\"LC\")\n",
    "        else:\n",
    "            cadence_col.append(\"SC\") \n",
    "    \n",
    "    with open(pyaneti_data_file, \"a\", newline='') as f:\n",
    "        writer = csv.writer(f, delimiter='\\t')\n",
    "        writer.writerows(zip(alltime[pyaneti_mask],allflux[pyaneti_mask],allfluxerr[pyaneti_mask],cadence_col))  # Comment out for full data\n",
    "        #writer.writerows(zip(alltime,allflux,allfluxerr))  # Uncomment for full data\n",
    "\n",
    "    f.close()\n",
    "    fig, axes = plt.subplots(figsize=(20,7))\n",
    "    axes.plot(alltime[pyaneti_mask],allflux[pyaneti_mask], marker='o', lw =0)\n",
    "    plt.show()\n",
    "    print(\"Created cutout data file: \" + pyaneti_data_file)\n",
    "elif data_method == \"30MIN\":  # Option to export a full light curve of 30 minute cadence data if want to compare FFI lcs\n",
    "    # Data file - just the 2 days surrounding the dip (See below if full data file wanted - but it slows pyaneti down!)\n",
    "\n",
    "    #lc_collection.flux = lc_collection['sap_flux']\n",
    "    lc_30min = lc_collection.normalize().bin(30/24/60)\n",
    "    lc_30min.plot(lw = 0, marker = '.', ms = 1)\n",
    "\n",
    "    # Export file for pyaneti\n",
    "    with open(pyaneti_data_file, \"w\", newline='') as f:\n",
    "        writer = csv.writer(f, delimiter='\\t')\n",
    "        writer.writerow(['#time', 'flux', 'flux_err', 'cadence'])\n",
    "\n",
    "    alltime = lc_30min.remove_nans().time.btjd\n",
    "    allflux = lc_30min.remove_nans().flux\n",
    "    allfluxerr = lc_30min.remove_nans().flux_err\n",
    "\n",
    "    with open(pyaneti_data_file, \"a\", newline='') as f:\n",
    "        writer = csv.writer(f, delimiter='\\t')\n",
    "        writer.writerows(zip(alltime,allflux,allfluxerr)) \n",
    "\n",
    "    f.close()\n",
    "    fig, axes = plt.subplots(figsize=(20,7))\n",
    "    axes.plot(alltime,allflux, marker='o', lw =0)\n",
    "    plt.show()\n",
    "    print(\"Created 30 minute data file: \" + pyaneti_data_file)\n",
    "elif data_method == \"DETREND\":  # Option to export detrended LC\n",
    "    lc_detrend = lc_collection.normalize()\n",
    "\n",
    "    # Extract the time and fluxes\n",
    "    alltime = np.array(lc_detrend.remove_nans().time.btjd)\n",
    "    allflux = np.array(lc_detrend.remove_nans().flux.value)\n",
    "    allflux_err = np.array(lc_detrend.remove_nans().flux_err.value)\n",
    "\n",
    "    # to get a good fit you need to adjust these parameters\n",
    "\n",
    "    # the size of the cut-off window - ideally you want this to be a couple of times the transit duration\n",
    "    cutoutwindow_width = (transit_length/24)*1.5\n",
    "\n",
    "    # this is to mask out the transit event (the stellar trend will be fit to the data excluding this data)\n",
    "    # this widnow is marked on by the blue vertical lines\n",
    "    transit_mask = transit_length/24\n",
    "\n",
    "    # this is the order of the polynomial - don't go to high! I recommend no higher than 3. \n",
    "    polynomial_order = 2\n",
    "\n",
    "    detrend_pyaneti(TIC_no, transit_time, alltime, allflux, allflux_err,cutoutwindow_width, transit_mask, polynomial_order, save = True)\n",
    "\n",
    "    # the second panel shows the detrended LC - check that it looks okay. The data is automatically saved and ready for pyaneti.\n",
    "else:\n",
    "    print (\"Select an data method\")\n",
    "    \n",
    "# Export full data for plotting later\n",
    "\n",
    "lc_norm = lc_collection.normalize()\n",
    "# Export file for pyaneti\n",
    "with open(pyaneti_full_data_file, \"w\", newline='') as f:\n",
    "    writer = csv.writer(f, delimiter='\\t')\n",
    "    writer.writerow(['#time', 'flux', 'flux_err'])\n",
    "\n",
    "alltime = lc_norm.remove_nans().time.btjd\n",
    "allflux = lc_norm.remove_nans().flux\n",
    "allfluxerr = lc_norm.remove_nans().flux_err\n",
    "\n",
    "with open(pyaneti_full_data_file, \"a\", newline='') as f:\n",
    "    writer = csv.writer(f, delimiter='\\t')\n",
    "    writer.writerows(zip(alltime,allflux,allfluxerr))  # Uncomment for full data\n",
    "\n",
    "f.close()\n",
    "#fig, axes = plt.subplots(figsize=(20,7))\n",
    "#axes.plot(alltime,allflux, marker='o', lw =0)\n",
    "#plt.show()\n",
    "print(\"Created full data file: \" + pyaneti_full_data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ad1a56-9283-49f6-900d-29cd135e99da",
   "metadata": {},
   "source": [
    "# Create the Pyaneti command file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bf1335-ea20-44d0-908f-38d709607e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pyaneti input data file\n",
    "template = \"\"\"#Input file for pyaneti\n",
    "#fname_tr contains the transit data\n",
    "fname_tr = ['{pyaneti_data_filename}']\n",
    "'''\n",
    "TIC {TIC_no}\n",
    "Sectors {sectors}\n",
    "{no_transits} Transits {transit_time}\n",
    "Light Curve {data_method}\n",
    "'''\n",
    "#MCMC controls\n",
    "#the thin factor for the chains\n",
    "thin_factor = 10\n",
    "#The number of iterations to be taken into account\n",
    "#The TOTAL number of iterations for the burn-in phase is thin_factor*niter\n",
    "niter       = 500\n",
    "#Number of independent Markov chains for the ensemble sampler\n",
    "nchains     = 100\n",
    "\n",
    "#Choose the method that we want to use\n",
    "# mcmc -> runs the mcmc fit program\n",
    "# plot -> this option create the plots only if a previus run was done\n",
    "method = 'mcmc'\n",
    "#method = 'plot'\n",
    "\n",
    "#bands\n",
    "{bands}\n",
    "\n",
    "#If you want a plot with the seaborn library, is_seaborn_plot has to be True\n",
    "is_seaborn_plot = False\n",
    "plot_binned_data = True\n",
    "\n",
    "#Set this true for multi-band\n",
    "is_jitter_tr = {is_jitter_tr}\n",
    "\n",
    "#Define the star parameters to calculate the planet parameters\n",
    "mstar_mean  = {pya_mass:0.04f}  # {mass_source}\n",
    "mstar_sigma = {pya_emass:0.04f}\n",
    "rstar_mean  = {pya_rad:0.04f}  # {radius_source}\n",
    "rstar_sigma = {pya_erad:0.04f}\n",
    "tstar_mean  = {pya_Teff:0.04f}  # {Teff_source}\n",
    "tstar_sigma = {pya_eTeff:0.04f}\n",
    "\n",
    "#What units do you prefer for your planet parameters?\n",
    "# earth, jupiter or solar\n",
    "unit_mass = 'earth'\n",
    "\n",
    "#If we want posterior, correlation and/or chain plots these options have to be set True\n",
    "is_plot_posterior    = True\n",
    "is_plot_correlations = True\n",
    "is_plot_chains       = False\n",
    "\n",
    "nplanets = 1\n",
    "\n",
    "#Are we setting gaussian priors on the semi-major axis based on the stellar parameters?\n",
    "a_from_kepler = [True]*nplanets\n",
    "\n",
    "#We want to fit transit and RV \n",
    "#For a pure RV fit, fit_tr has to be False\n",
    "#For a pure TR fit, fit_rv has to be False\n",
    "#For multi-planet fits fit_rv and fit_tr have the form [True,True,False,...]\n",
    "#one element for each planet.\n",
    "fit_rv = [False]*nplanets\n",
    "fit_tr = [True]*nplanets\n",
    "\n",
    "#is_ew controls the parametrization sqrt(e)sin w and sqrt(e) cos w\n",
    "#if True we fit for the parametrization parameters\n",
    "#if False we fit for e and w\n",
    "#Default is True\n",
    "is_ew = False\n",
    "\n",
    "# Change the next line to False and alter a priors if you want to use a/R* rather than density\n",
    "sample_stellar_density = {sample_stellar_density}\n",
    "\n",
    "#Prior section\n",
    "# f -> fixed value\n",
    "# u -> Uniform priors\n",
    "# g -> Gaussian priors\n",
    "fit_t0 = ['u']*nplanets   #We fit for t0 with uniform priors\n",
    "fit_P  = ['u']*nplanets   #We fit for P with uniform priors\n",
    "fit_ew1= ['f']*nplanets   #We fit sqrt(e) sin w, it works only if is_ew = True - Change to u to model eccentricity\n",
    "fit_ew2= ['f']*nplanets   #We fit sqrt(e) cos w, it works only if is_ew = True - Change to u to model eccentricity\n",
    "fit_e  = ['f']*nplanets   #We fix e, it works only if is_ew = False\n",
    "fit_w  = ['f']*nplanets   #We fix w, it works only if is_ew = False\n",
    "fit_b  = ['u']*nplanets   #We fit the impact factor\n",
    "fit_a  = ['{fit_a}']*nplanets   #{fit_a_comment}\n",
    "fit_rp = ['u']*nplanets   #We fit rp with uniform priors\n",
    "fit_k  = ['u']*nplanets   #We fit k with uniform priors\n",
    "fit_v0 = 'u'     #We fit systemc velicities with uniform priors\n",
    "fit_q1 = ['u']*{nbands}     #We fit q1 with uniform priors\n",
    "fit_q2 = ['u']*{nbands}     #We fit q2 with uniform priors\n",
    "\n",
    "#Prior ranges for a parameter A\n",
    "#if 'f' is selected for the parameter A, A is fixed to the one given by min_A\n",
    "#if 'u' is selected for the parameter A, sets uniform priors between min_A and max_A\n",
    "#if 'g' is selected for the parameter A, sets gaussian priors with mean min_A and standard deviation max_A\n",
    "\n",
    "min_t0  = [{transit_0_lower:0.04f}] \n",
    "max_t0  = [{transit_0_upper:0.04f}]  \n",
    "min_P   = [{period_lower}]\n",
    "max_P   = [{period_upper}]\n",
    "min_ew1 = [0.0]*nplanets  # Change to -1 if modelling ew\n",
    "min_ew2 = [0.0]*nplanets  # Change to -1 if modelling ew\n",
    "max_ew1 = [1.0]*nplanets\n",
    "max_ew2 = [1.0]*nplanets\n",
    "min_e   = [0]*nplanets\n",
    "max_e   = [1]*nplanets\n",
    "min_w   = [0]*nplanets\n",
    "max_w   = [2*np.pi]*nplanets\n",
    "min_a   = [{min_a}]*nplanets\n",
    "max_a   = [{max_a}]*nplanets\n",
    "min_b   = [0.0]*nplanets\n",
    "max_b   = [1.15]*nplanets\n",
    "min_k   = [0.0]*nplanets\n",
    "max_k   = [0.001]*nplanets\n",
    "min_rp  = [{prad_min:0.04f}]\n",
    "max_rp  = [{prad_max:0.04f}]\n",
    "min_q1  = [0.0]*{nbands} \n",
    "max_q1  = [1.0]*{nbands} \n",
    "min_q2  = [0.0]*{nbands} \n",
    "max_q2  = [1.0]*{nbands} \n",
    "\n",
    "\"\"\" \n",
    "context = {\n",
    "\"pyaneti_data_filename\":pyaneti_data_filename,  \n",
    "\"TIC_no\":TIC_no,\n",
    "\"sectors\":sectors,\n",
    "\"no_transits\":len(transit_time),\n",
    "\"transit_time\":transit_time,\n",
    "\"data_method\":data_method,\n",
    "\"bands\":bands,\n",
    "\"radius_source\":radius_source,\n",
    "\"mass_source\":mass_source,\n",
    "\"Teff_source\":Teff_source,\n",
    "\"is_jitter_tr\":is_jitter_tr,\n",
    "\"pya_mass\":float(pya_mass),\n",
    "\"pya_emass\":float(pya_emass), \n",
    "\"pya_rad\":float(pya_rad),     \n",
    "\"pya_erad\":float(pya_erad),    \n",
    "\"pya_Teff\":float(pya_Teff),     \n",
    "\"pya_eTeff\":float(pya_eTeff),\n",
    "\"sample_stellar_density\":sample_stellar_density,\n",
    "\"fit_a\":fit_a,\n",
    "\"fit_a_comment\":fit_a_comment,\n",
    "\"min_a\":min_a,\n",
    "\"max_a\":max_a,\n",
    "\"transit_0_lower\":transit_time[0]-0.03,\n",
    "\"transit_0_upper\":transit_time[0]+0.03,\n",
    "\"period_lower\":period*.99,\n",
    "\"period_upper\":period*1.01,\n",
    "\"prad_min\":r_pl_solar_radius.value*0.2,\n",
    "\"prad_max\":r_pl_solar_radius.value*2,\n",
    "\"nbands\":nbands\n",
    "} \n",
    "#print(context)\n",
    "\n",
    "with open(pyaneti_input_file, \"w\", newline='') as f:\n",
    "    #writer = csv.writer(f, delimiter='\\t')\n",
    "    f.write(template.format(**context))\n",
    "    \n",
    "f.close()\n",
    "print(\"Created \" + pyaneti_input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26a897e-4f1c-4fe0-9d1e-50b9e2def831",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gedit $pyaneti_input_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f5c686-c218-4e6c-8310-f9765d5e7f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "!echo Running Pyaneti\n",
    "!cd $pyaneti_home_dir ; $pyaneti_command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d2a719-ff78-421d-ae1e-47f923f1a7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaneti_utils as py\n",
    "%matplotlib widget\n",
    "py.display_results(TIC_no,target_out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188cac39-ccc1-434b-b88c-d12b86a64cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pyaneti_home_dir = \"/home/ian/pyaneti\"\n",
    "#!cd $pyaneti_home_dir ; python pyaneti.py 312543349"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e4a2cf-db6f-4801-abd7-f4d10c7ab33b",
   "metadata": {},
   "source": [
    "# Publish in PHT Shared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1694782-f7d9-40c0-8e0f-cfc0ca755d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from distutils.dir_util import copy_tree\n",
    "\n",
    "publish_dir = '/mnt/g/Google Drive/Astrophysics/PHT Shared/{}{}/'.format(TIC_no,model_suffix)\n",
    "print(publish_dir)\n",
    "# Save the params `.dat` as `.txt` so that it can be easily viewed on Google Drive.\n",
    "file_params = Path(target_out_dir, f\"{TIC_no}_params.dat\")\n",
    "file_params_txt = Path(target_out_dir, f\"{TIC_no}_params.txt\")\n",
    "shutil.copyfile(file_params, file_params_txt)\n",
    "\n",
    "# Copy `input_fit.py` and input data file to output directory so that it can be easily shared (on Google Drive).\n",
    "destination = Path(target_out_dir, input_fit_filename)\n",
    "shutil.copyfile(pyaneti_input_file, destination)\n",
    "destination = Path(target_out_dir, pyaneti_data_filename)\n",
    "shutil.copyfile(pyaneti_data_file, destination)\n",
    "\n",
    "try:\n",
    "    shutil.rmtree(publish_dir)\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    os.mkdir(publish_dir)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Publish to PHT Shared and rename the model directories to preserve them\n",
    "copy_tree(target_out_dir, publish_dir)\n",
    "try:\n",
    "    shutil.rmtree(target_out_dir + model_suffix)\n",
    "except:\n",
    "    pass\n",
    "shutil.move(target_out_dir, target_out_dir + model_suffix)\n",
    "try:\n",
    "    shutil.rmtree(target_in_dir + model_suffix)\n",
    "except:\n",
    "    pass\n",
    "shutil.move(target_in_dir, target_in_dir + model_suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592201d0-65ec-42af-9751-c5b688a98c6c",
   "metadata": {},
   "source": [
    "# Google publish\n",
    "To publish Google Drive links in discussion:\n",
    "https://drive.google.com/uc?export=view&id=\n",
    "\n",
    "- Add the image's id to the end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5925bb-dd58-481e-843c-e02836844221",
   "metadata": {},
   "source": [
    "# Odd-Even Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a4db3f-164b-4f53-b60c-267695b5fcc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def odd_even_phase(lc, period, t0, plot_size = False, same_axes = False, binning = False):\n",
    "    \n",
    "    lc = lc.normalize()\n",
    "    \n",
    "    if binning != False:\n",
    "        lc = lc.bin(binning/60/24) # you can change the binning factor here if you like\n",
    "    time = lc.time.value\n",
    "    flux = lc.flux.value\n",
    "    \n",
    "    t0_odd = t0\n",
    "    t0_even = t0 + period\n",
    "    period = period*2\n",
    "    \n",
    "    phase_odd = np.array([-0.5+( ( t - t0_odd-0.5*period) % period) / period for t in time])\n",
    "    phase_even = np.array([-0.5+( ( t - t0_even-0.5*period) % period) / period for t in time])\n",
    "\n",
    "    if same_axes == False:\n",
    "        fig, ax = plt.subplots(1,2, figsize = (20,8), sharey = True)\n",
    "        \n",
    "        ax[0].plot(phase_odd, flux, lw = 0, color = 'navy', marker = '.', alpha =0.4)\n",
    "        ax[1].plot(phase_even, flux, lw = 0, color = 'maroon', marker = '.', alpha =0.4)\n",
    "        \n",
    "        ax[0].set_xlabel(\"Phase\")\n",
    "        ax[0].set_ylabel(\"Normalized flux\")\n",
    "        ax[1].set_xlabel(\"Phase\")\n",
    "        \n",
    "        ax[0].annotate(\"ODD\", (0.3, np.nanmin(flux)), fontsize = 14)\n",
    "        ax[1].annotate(\"EVEN\", (0.3, np.nanmin(flux)), fontsize = 14)\n",
    "    \n",
    "        plt.subplots_adjust(wspace=0.02)\n",
    "        \n",
    "        if plot_size != False:\n",
    "            ax[0].set_xlim(-plot_size, plot_size)\n",
    "            ax[1].set_xlim(-plot_size, plot_size)\n",
    "    else:\n",
    "        fig, ax = plt.subplots(figsize = (10,8))\n",
    "        \n",
    "        ax.plot(phase_odd, flux, lw = 0, color = 'navy', marker = '.', alpha =0.4, label = 'odd')\n",
    "        ax.plot(phase_even, flux, lw = 0, color = 'maroon', marker = '.', alpha =0.4, label = 'even')\n",
    "        \n",
    "        ax.set_xlabel(\"Phase\")\n",
    "        ax.set_ylabel(\"Normalized flux\")\n",
    "        \n",
    "        plt.legend()\n",
    "            \n",
    "        if plot_size != False:\n",
    "            ax.set_xlim(-plot_size, plot_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a8410b-49ab-478e-bef0-7a2f01e5d466",
   "metadata": {},
   "outputs": [],
   "source": [
    "#period = transits[1] - transits[0]\n",
    "t0 = transit_time[0]\n",
    "%matplotlib widget\n",
    "plt.style.use('default')\n",
    "odd_even_phase(lc_collection, period, t0=t0, plot_size = 0.05, same_axes = False, binning=True)\n",
    "period"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bca1e4-7a89-4ff7-8add-d96b67e37cd8",
   "metadata": {},
   "source": [
    "# Periodogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33739cb0-732a-46e1-8baf-3d311564a8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg = lc_collection.to_periodogram(maximum_period=100)\n",
    "pg.plot(view='period');\n",
    "print(pg.period_at_max_power)\n",
    "print(pg.period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90015df7-117a-4516-bda4-adcce1b73a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model light curve for the highest peak in the periodogram\n",
    "lc_model = pg.model(time=lc_collection.time, frequency=pg.frequency_at_max_power)\n",
    "# Plot the light curve\n",
    "axper = lc_collection.plot()\n",
    "# Plot the model light curve on top\n",
    "lc_model.plot(ax=axper, lw=3, ls='--', c='red');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb977ea-be94-4f46-9f4a-04cad51449fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the signals associated with the 50 highest peaks\n",
    "newlc = lc_collection.copy()\n",
    "for i in range(50):\n",
    "  pg = newlc.to_periodogram()\n",
    "  model = pg.model(time=newlc.time, frequency=pg.frequency_at_max_power)\n",
    "  newlc.flux = newlc.flux / model.flux\n",
    "\n",
    "# Plot the new light curve on top of the original one\n",
    "axper1 = lc_collection.plot(alpha=.5, label='Original',lw = 0, marker = '.', ms = 1);\n",
    "newlc.plot(ax=axper1, label='New');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99324ea5-4a6d-4410-8683-b22b76503b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folded\n",
    "period = 8.03\n",
    "axperf = newlc.fold(period=period, epoch_time = transit_time[0]).plot(label='Unbinned',lw = 0, marker = '.', ms = 1)\n",
    "newlc.fold(period=period, epoch_time = transit_time[0]).bin(0.1).plot(ax=axperf, lw=2, label='Binned');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e1ee12-6121-4d0d-88a5-ca22c014339f",
   "metadata": {},
   "source": [
    "# River Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bd3132-bb58-4e83-9cc7-32d2ebf53056",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "period = 12.0319985\n",
    "lcl = lc_collection\n",
    "#lcl = lcl.flatten(21)\n",
    "lcl_fold = lcl.fold(period = period, epoch_time = transit_time[0])\n",
    "lcl_fold.plot_river()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8604c999-ee60-4a7b-b0f0-b9d33fc44420",
   "metadata": {},
   "source": [
    "# Plot against known exoplanets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b04cbaf-45ce-41af-91ab-d959cd9d0f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check NASA Exoplanet Archive and retrieve planets with similar period and radius (within tolerance of each)\n",
    "import astropy.units as u\n",
    "from astropy.time import Time\n",
    "from astroquery.ipac.nexsci.nasa_exoplanet_archive import NasaExoplanetArchive\n",
    "import numpy as np\n",
    "\n",
    "period_c =  float(period)\n",
    "radius_c = r_pl_jup_radius.value\n",
    "\n",
    "tolerance = 0.25\n",
    "\n",
    "query_string = \"(pl_orbper > %0.3f and pl_orbper < %0.3f) and (pl_radj > %0.3f and pl_radj < %0.3f)\" %(period_c-(period_c*tolerance), period_c+(period_c*tolerance), radius_c-(radius_c*tolerance), radius_c+(radius_c*tolerance))\n",
    "print(query_string)\n",
    "planet_data = NasaExoplanetArchive.query_criteria(table=\"pscomppars\", where=query_string, order=\"hostname\")\n",
    "if len(planet_data) > 0:\n",
    "    planets = np.array(planet_data)  #extract table data into an array\n",
    "    planets_df = pd.DataFrame(planets, columns=[\"pl_name\",\"disc_year\",\"pl_orbper\",\"pl_trandur\",\"pl_radj\",\"pl_rade\",\"st_rad\",\"st_teff\"])  #create a pandas data frame from the array and the headers\n",
    "    print(planets_df)\n",
    "else:\n",
    "    print (\"No Planets found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109ea01f-f821-4ba9-b9d0-b2a5f2a5d3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "per=np.array(planet_data[\"pl_orbper\"])\n",
    "rad=np.array(planet_data[\"pl_radj\"])\n",
    "st_rad=np.array(planet_data[\"st_rad\"])\n",
    "teff=np.array(planet_data['st_teff'])\n",
    "\n",
    "fig_plan, ax_plan = plt.subplots(figsize=(10, 10))\n",
    "sc = plt.scatter(per, rad, s=st_rad*50, c = np.log(teff), cmap = 'RdYlBu', alpha = 0.9, zorder = -1, edgecolors = 'white', linewidths = 0.1)\n",
    "sc.set_clim(np.log(2500), np.log(20000))\n",
    "sc_target = plt.scatter(period_c,radius_c,s=R_star*50, c = np.log(TIC_Teff), cmap = 'RdYlBu', alpha = 0.8, zorder = -1, edgecolors = 'black', linewidths = 0.5)\n",
    "sc_target.set_clim(np.log(2500), np.log(20000))\n",
    "for i, txt in enumerate(planet_data[\"pl_name\"]):\n",
    "    ax_plan.annotate(txt, (per[i], rad[i]),color='grey',fontsize=10,textcoords=\"offset points\",xytext=(4,3))  # Test is offest from the point by the xytext value\n",
    "ax_plan.annotate(TIC, (period_c,radius_c),color='grey',fontsize=10,textcoords=\"offset points\",xytext=(4,3))\n",
    "\n",
    "plt.xlabel('Period (d)')\n",
    "plt.ylabel('Radius (Rjup)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a807c14d-28ca-40a9-bae6-0331939c5d2c",
   "metadata": {},
   "source": [
    "# Create star chart round a target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf23acf-4245-4b18-9ca4-220410065f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import star_data as star\n",
    "TIC_Teff, TIC_lum, TIC_rad = star.plot_star_chart(TIC_no)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8af333-9808-4599-801e-462d8f55d0ea",
   "metadata": {},
   "source": [
    "# HR Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2d4d04-e7c1-46bc-bf35-d5dfc9c7c1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import star_data as star\n",
    "star.plot_HR(TIC_no, TIC_Teff, TIC_lum, TIC_rad, TOI = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974676fa-0585-4210-8b9f-26ed4610c7ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "# Export file for pyaneti\n",
    "with open('{}/{}_data_pyaneti.dat'.format(TIC_no, TIC_no), \"w\") as f:\n",
    "    writer = csv.writer(f, delimiter='\\t')\n",
    "    writer.writerow(['#time', 'flux', 'flux_err'])\n",
    "\n",
    "# If the dip separations are too small, then don't create cut outs and save the whole dataset\n",
    "#if (len(transit_list) > 1) and ((transit_list[1] - transit_list[0]) < 2): # if there are LOTS of transit events on short period (if so it's probably a TOI but let's keep it here as a condition)\n",
    "with open('{}/{}_data_pyaneti.dat'.format(TIC_no, TIC_no), \"a\") as f:\n",
    "    writer = csv.writer(f, delimiter='\\t')\n",
    "    writer.writerows(zip(lc_collection.remove_nans().time,lc_collection.remove_nans().flux,lc_collection.remove_nans().flux_err)) # save all the data\n",
    "\n",
    "# else create a cut out of the data around the time of the transit events\n",
    "#else:\n",
    "#    for transit in transit_list:\n",
    "#        # save the data \n",
    "#        # get rid of nan values first - this is used for the pyaneti code\n",
    "#        pyaneti_mask = (alltime_ar > (transit - 1)) * (alltime_ar < (transit + 1))\n",
    "\n",
    "#        with open('{}/{}/{}_data_pyaneti.dat'.format(indir, tic, tic), \"a\") as f:\n",
    "#            writer = csv.writer(f, delimiter='\\t')\n",
    "#            writer.writerows(zip(alltime_ar[pyaneti_mask],allflux_ar[pyaneti_mask],allflux_err_ar[pyaneti_mask]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8376972a-c76e-4628-b328-62022ef92f54",
   "metadata": {},
   "source": [
    "# Old Calc actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fde0e3a-c645-42dc-b29c-e7bcaee8446a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Click event to select the TOP and BOTTOM of the Transit \n",
    "def onclick(event):\n",
    "    global ix, iy\n",
    "    ix, iy = event.xdata, event.ydata\n",
    "    if event.button == 3:  # Only act on a right click\n",
    "        global coords\n",
    "\n",
    "        if len(coords) == 0:  # remove any existing markers if this is the first click\n",
    "            try: \n",
    "                tran[0].remove()\n",
    "            except:\n",
    "                pass\n",
    "            try: \n",
    "                tran[1].remove()\n",
    "            except:\n",
    "                pass\n",
    "            tran.clear()\n",
    "\n",
    "        coords.append((ix, iy))\n",
    "        tran.append(plt.axhline(iy, color = 'orange', zorder = -1))\n",
    "\n",
    "        if len(coords) == 2:\n",
    "            fig.canvas.mpl_disconnect(cid)\n",
    "            \n",
    "# Click event to select the START and END of the Transit \n",
    "def onclick1(event):\n",
    "    global ix, iy\n",
    "    ix, iy = event.xdata, event.ydata\n",
    "    if event.button == 3:  # Only act on a right click\n",
    "        global coords\n",
    "\n",
    "        if len(coords) == 0:  # remove any existing markers if this is the first click\n",
    "            try: \n",
    "                tran[0].remove()\n",
    "            except:\n",
    "                pass\n",
    "            try: \n",
    "                tran[1].remove()\n",
    "            except:\n",
    "                pass\n",
    "            tran.clear()\n",
    "\n",
    "        coords.append((ix, iy))\n",
    "        tran.append(plt.axvline(ix, color = 'blue', zorder = -1))\n",
    "\n",
    "        if len(coords) == 2:\n",
    "            fig.canvas.mpl_disconnect(cid)\n",
    "            \n",
    "# Click event to select the Floor START and END of the Transit \n",
    "def onclick2(event):\n",
    "    global ix, iy\n",
    "    ix, iy = event.xdata, event.ydata\n",
    "    if event.button == 3:  # Only act on a right click\n",
    "        global coords\n",
    "\n",
    "        if len(coords) == 0:  # remove any existing markers if this is the first click\n",
    "            try: \n",
    "                tran[0].remove()\n",
    "            except:\n",
    "                pass\n",
    "            try: \n",
    "                tran[1].remove()\n",
    "            except:\n",
    "                pass\n",
    "            tran.clear()\n",
    "\n",
    "        coords.append((ix, iy))\n",
    "        tran.append(plt.axvline(ix, color = 'grey', linestyle = '-', zorder = -1))\n",
    "\n",
    "        if len(coords) == 2:\n",
    "            fig.canvas.mpl_disconnect(cid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44f84cc-7dde-4564-9757-6e5676722e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on the TOP and BOTTOM, then run this = transit depth\n",
    "\n",
    "transit_top = coords[0][1] \n",
    "transit_bottom = coords[1][1] \n",
    "coords.clear()\n",
    "cid = fig.canvas.mpl_connect('button_press_event', onclick)  # Reconnect the event in case we change our mind\n",
    "\n",
    "transit_depth = transit_top-transit_bottom\n",
    "if transit_depth < 0 : transit_depth *= -1  # In case we choose the wrong way round\n",
    "print ('Transit Depth = %6.4f' %(transit_depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998e5e77-151a-44c8-8b24-5a9c914e0763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When happy with top/bottom, run this to initialise event to select the START and END of the Transit - run this first\n",
    "\n",
    "fig.canvas.mpl_disconnect(cid)\n",
    "tran.clear()\n",
    "\n",
    "cid = fig.canvas.mpl_connect('button_press_event', onclick1)  # Connect the event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd096c88-c06b-42ad-b54c-a10b29766dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on the START and END then run this = transit length\n",
    "\n",
    "transit_start = coords[0][0] \n",
    "transit_end = coords[1][0] \n",
    "coords = []\n",
    "cid = fig.canvas.mpl_connect('button_press_event', onclick1)  # Reconnect the event in case we change our mind\n",
    "\n",
    "transit_length = (transit_end-transit_start) * 24\n",
    "if transit_length < 0 : transit_length *= -1  # In case we choose the wrong way round\n",
    "print ('Transit Length = %6.4f hours' %(transit_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ed6fbd-63f1-4fdb-9900-f81588e60349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When happy with start/end, run this to initialise event to select the START and END of the Floor - run this first\n",
    "\n",
    "fig.canvas.mpl_disconnect(cid)\n",
    "tran.clear()\n",
    "\n",
    "cid = fig.canvas.mpl_connect('button_press_event', onclick2)  # Connect the event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ac2425-c99c-4f1b-8fb1-9c7bece1bcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on the START and END of the floor then run this = Floor length\n",
    "\n",
    "floor_start = coords[0][0] \n",
    "floor_end = coords[1][0] \n",
    "coords = []\n",
    "cid = fig.canvas.mpl_connect('button_press_event', onclick2)  # Reconnect the event in case we change our mind\n",
    "\n",
    "floor_length = (floor_end-floor_start) * 24\n",
    "if floor_length < 0 : floor_length *= -1  # In case we choose the wrong way round\n",
    "print ('Floor Length = %6.4f hours' %(floor_length))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
